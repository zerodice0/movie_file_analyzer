"""ë¶„ì„ ëª…ë ¹ì–´."""

from __future__ import annotations

from pathlib import Path
from typing import Optional

from ..utils import check_dependencies
from ...core.ai_connector import AIConnectorFactory
from ...core.context_optimizer import ContextOptimizer
from ...core.frame_extractor import FrameExtractor
from ...data.metadata_store import MetadataStore
from ...data.models import AnalysisRecord
from ...utils.cache_manager import CacheManager


def analyze_command(
    video_path: Path,
    interval: Optional[float] = None,
    model: str = "auto",
    language: str = "korean",
    custom_prompt: Optional[str] = None,
    save_sidecar: bool = True,
    save_history: bool = True,
    cleanup_cache: bool = True,
    output_format: str = "text",
) -> dict:
    """
    ì˜ìƒì„ ë¶„ì„í•©ë‹ˆë‹¤.

    Args:
        video_path: ì˜ìƒ íŒŒì¼ ê²½ë¡œ
        interval: ì¶”ì¶œ ê°„ê²© (ì´ˆ), Noneì´ë©´ ìë™ ê³„ì‚°
        model: Gemini ëª¨ë¸
        language: ì¶œë ¥ ì–¸ì–´
        custom_prompt: ì‚¬ìš©ì ì •ì˜ í”„ë¡¬í”„íŠ¸
        save_sidecar: ì‚¬ì´ë“œì¹´ JSON ì €ì¥ ì—¬ë¶€
        save_history: íˆìŠ¤í† ë¦¬ ì €ì¥ ì—¬ë¶€
        cleanup_cache: ë¶„ì„ í›„ ìºì‹œ ì •ë¦¬ ì—¬ë¶€
        output_format: ì¶œë ¥ í˜•ì‹ (text/json)

    Returns:
        dict: ë¶„ì„ ê²°ê³¼
    """
    result = {
        "success": False,
        "video_path": str(video_path),
        "analysis": "",
        "error": None,
        "metadata": {},
    }

    # ì˜ì¡´ì„± í™•ì¸
    deps = check_dependencies()
    if not deps["ffmpeg"] or not deps["ffprobe"]:
        result["error"] = "FFmpegê°€ ì„¤ì¹˜ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤."
        return result

    if not deps["gemini"]:
        result["error"] = "Gemini CLIê°€ ì„¤ì¹˜ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤."
        return result

    if not video_path.exists():
        result["error"] = f"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {video_path}"
        return result

    try:
        result = _perform_analysis(
            video_path, interval, model, language,
            custom_prompt, save_sidecar, save_history, cleanup_cache
        )
    except Exception as e:
        result["error"] = str(e)

    return result


def _perform_analysis(
    video_path: Path,
    interval: Optional[float],
    model: str,
    language: str,
    custom_prompt: Optional[str],
    save_sidecar: bool,
    save_history: bool,
    cleanup_cache: bool,
) -> dict:
    """ì‹¤ì œ ë¶„ì„ ìˆ˜í–‰."""
    result = {
        "success": False,
        "video_path": str(video_path),
        "analysis": "",
        "error": None,
        "metadata": {},
    }

    extractor = FrameExtractor()
    video_info = extractor.get_video_info(video_path)

    print(f"\nğŸ“¹ ì˜ìƒ ì •ë³´")
    print(f"   íŒŒì¼: {video_path.name}")
    print(f"   ê¸¸ì´: {video_info.duration_str}")
    print(f"   í•´ìƒë„: {video_info.width}x{video_info.height}")
    print(f"   í¬ê¸°: {video_info.size_mb:.1f}MB")

    # ì¶”ì¶œ ê°„ê²© ìë™ ê³„ì‚°
    if interval is None:
        optimizer = ContextOptimizer()
        strategy = optimizer.calculate_strategy(video_info.duration)
        interval = strategy.interval_seconds
        print(f"\nğŸ”§ ìë™ ìµœì í™”")
        print(f"   ì¶”ì¶œ ê°„ê²©: {interval}ì´ˆ")
        print(f"   ì˜ˆìƒ í”„ë ˆì„: {strategy.estimated_frames}ê°œ")

    # ìºì‹œ ë° í”„ë ˆì„ ì¶”ì¶œ
    cache_manager = CacheManager(auto_cleanup=cleanup_cache)
    frames_dir = cache_manager.create_cache_dir(video_path)

    print(f"\nğŸ–¼ï¸  í”„ë ˆì„ ì¶”ì¶œ ì¤‘...")
    frames = extractor.extract_frames(video_path, frames_dir, interval=interval)
    print(f"   ì¶”ì¶œ ì™„ë£Œ: {len(frames)}ê°œ í”„ë ˆì„")

    # AI ë¶„ì„
    print(f"\nğŸ¤– AI ë¶„ì„ ì¤‘ (ëª¨ë¸: {model})...")
    connector = AIConnectorFactory.create("gemini", model=model)
    analysis_result = connector.analyze(
        frame_paths=frames,
        interval_sec=interval,
        duration_str=video_info.duration_str,
        custom_prompt=custom_prompt,
        output_language=language,
        working_dir=frames_dir,
    )

    if not analysis_result.success:
        result["error"] = analysis_result.error_message
        return result

    # ê²°ê³¼ êµ¬ì„±
    result["success"] = True
    result["analysis"] = analysis_result.result
    result["metadata"] = {
        "video_name": video_path.name,
        "video_duration": video_info.duration,
        "video_resolution": f"{video_info.width}x{video_info.height}",
        "frame_count": len(frames),
        "interval_seconds": interval,
        "model": model,
        "language": language,
    }

    # ë¶„ì„ ê¸°ë¡ ì €ì¥
    if save_sidecar or save_history:
        _save_record(
            video_path, video_info, interval, frames,
            analysis_result, save_sidecar, save_history
        )
        result["record_id"] = None  # record.idë¥¼ ë³„ë„ë¡œ ì–»ì„ ìˆ˜ ìˆìŒ

    # ìºì‹œ ì •ë¦¬
    if cleanup_cache:
        cache_manager.cleanup_video_cache(video_path)
        print(f"\nğŸ—‘ï¸  ìºì‹œ ì •ë¦¬ ì™„ë£Œ")

    print(f"\nâœ… ë¶„ì„ ì™„ë£Œ!")
    return result


def _save_record(
    video_path: Path,
    video_info,
    interval: float,
    frames: list,
    analysis_result,
    save_sidecar: bool,
    save_history: bool,
):
    """ë¶„ì„ ê¸°ë¡ ì €ì¥."""
    record = AnalysisRecord(
        video_path=str(video_path),
        video_name=video_path.name,
        video_duration=video_info.duration,
        video_resolution=(video_info.width, video_info.height),
        video_size_mb=video_info.size_mb,
        extraction_mode="interval" if interval else "all_iframes",
        extraction_interval=interval,
        frame_count=len(frames),
        ai_provider="Gemini",
        prompt_used=analysis_result.prompt_used,
        analysis_result=analysis_result.result,
    )

    store = MetadataStore()
    store.save(record, save_sidecar=save_sidecar, save_to_history=save_history)
