#!/usr/bin/env python3
"""Movie File Analyzer CLI - Claude Code ìŠ¤í‚¬ìš© ëª…ë ¹ì¤„ ì¸í„°í˜ì´ìŠ¤."""

from __future__ import annotations

import argparse
import json
import re
import sys
from pathlib import Path
from typing import Optional

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ PYTHONPATHì— ì¶”ê°€
sys.path.insert(0, str(Path(__file__).parent.parent))

from src.core.ai_connector import AIConnectorFactory, GeminiConnector
from src.core.context_optimizer import ContextOptimizer
from src.core.frame_extractor import FrameExtractor
from src.data.metadata_store import MetadataStore
from src.data.models import AnalysisRecord, AppConfig
from src.utils.cache_manager import CacheManager


def check_dependencies() -> dict[str, bool]:
    """ì˜ì¡´ì„± ì„¤ì¹˜ ìƒíƒœë¥¼ í™•ì¸í•©ë‹ˆë‹¤."""
    import shutil

    return {
        "ffmpeg": shutil.which("ffmpeg") is not None,
        "ffprobe": shutil.which("ffprobe") is not None,
        "gemini": shutil.which("gemini") is not None,
        "yt-dlp": shutil.which("yt-dlp") is not None or shutil.which("yt_dlp") is not None,
    }


def print_status():
    """ì˜ì¡´ì„± ìƒíƒœë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤."""
    deps = check_dependencies()

    print("\nğŸ“¦ ì˜ì¡´ì„± ìƒíƒœ")
    print("=" * 50)

    for name, installed in deps.items():
        status = "âœ… ì„¤ì¹˜ë¨" if installed else "âŒ ë¯¸ì„¤ì¹˜"
        required = "(í•„ìˆ˜)" if name in ["ffmpeg", "ffprobe", "gemini"] else "(ì„ íƒ)"
        print(f"  {name}: {status} {required}")

    print()


def is_youtube_url(url: str) -> bool:
    """YouTube URLì¸ì§€ í™•ì¸í•©ë‹ˆë‹¤."""
    youtube_patterns = [
        r'(https?://)?(www\.)?youtube\.com/watch\?v=',
        r'(https?://)?(www\.)?youtu\.be/',
        r'(https?://)?(www\.)?youtube\.com/shorts/',
    ]
    return any(re.match(pattern, url) for pattern in youtube_patterns)


def download_youtube(url: str, output_dir: Optional[Path] = None) -> tuple[bool, str, Optional[Path]]:
    """YouTube ì˜ìƒì„ ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤."""
    try:
        from src.core.youtube_downloader import YouTubeDownloader

        downloader = YouTubeDownloader()
        if not downloader.is_available():
            return False, "yt-dlpê°€ ì„¤ì¹˜ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.", None

        if output_dir is None:
            output_dir = Path.home() / ".movie_file_analyzer" / "downloads"
        output_dir.mkdir(parents=True, exist_ok=True)

        print(f"ğŸ”„ YouTube ì˜ìƒ ë‹¤ìš´ë¡œë“œ ì¤‘: {url}")

        # ì§„í–‰ë¥  ì½œë°±
        def progress_callback(progress):
            if progress.percent:
                print(f"   ì§„í–‰ë¥ : {progress.percent:.1f}%", end="\r")

        result = downloader.download(url, output_dir, progress_callback=progress_callback)
        print()  # ì¤„ë°”ê¿ˆ

        if result.success:
            return True, f"ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {result.file_path}", result.file_path
        else:
            return False, f"ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {result.error_message}", None

    except ImportError:
        return False, "YouTube ë‹¤ìš´ë¡œë” ëª¨ë“ˆì„ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.", None
    except Exception as e:
        return False, f"ë‹¤ìš´ë¡œë“œ ì˜¤ë¥˜: {e}", None


def analyze_video(
    video_path: Path,
    interval: Optional[float] = None,
    model: str = "auto",
    language: str = "korean",
    custom_prompt: Optional[str] = None,
    save_sidecar: bool = True,
    save_history: bool = True,
    cleanup_cache: bool = True,
    output_format: str = "text",
) -> dict:
    """
    ì˜ìƒì„ ë¶„ì„í•©ë‹ˆë‹¤.

    Args:
        video_path: ì˜ìƒ íŒŒì¼ ê²½ë¡œ
        interval: ì¶”ì¶œ ê°„ê²© (ì´ˆ), Noneì´ë©´ ìë™ ê³„ì‚°
        model: Gemini ëª¨ë¸
        language: ì¶œë ¥ ì–¸ì–´
        custom_prompt: ì‚¬ìš©ì ì •ì˜ í”„ë¡¬í”„íŠ¸
        save_sidecar: ì‚¬ì´ë“œì¹´ JSON ì €ì¥ ì—¬ë¶€
        save_history: íˆìŠ¤í† ë¦¬ ì €ì¥ ì—¬ë¶€
        cleanup_cache: ë¶„ì„ í›„ ìºì‹œ ì •ë¦¬ ì—¬ë¶€
        output_format: ì¶œë ¥ í˜•ì‹ (text/json)

    Returns:
        dict: ë¶„ì„ ê²°ê³¼
    """
    result = {
        "success": False,
        "video_path": str(video_path),
        "analysis": "",
        "error": None,
        "metadata": {},
    }

    # ì˜ì¡´ì„± í™•ì¸
    deps = check_dependencies()
    if not deps["ffmpeg"] or not deps["ffprobe"]:
        result["error"] = "FFmpegê°€ ì„¤ì¹˜ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤."
        return result

    if not deps["gemini"]:
        result["error"] = "Gemini CLIê°€ ì„¤ì¹˜ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤."
        return result

    if not video_path.exists():
        result["error"] = f"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {video_path}"
        return result

    try:
        # í”„ë ˆì„ ì¶”ì¶œê¸° ì´ˆê¸°í™”
        extractor = FrameExtractor()
        video_info = extractor.get_video_info(video_path)

        print(f"\nğŸ“¹ ì˜ìƒ ì •ë³´")
        print(f"   íŒŒì¼: {video_path.name}")
        print(f"   ê¸¸ì´: {video_info.duration_str}")
        print(f"   í•´ìƒë„: {video_info.width}x{video_info.height}")
        print(f"   í¬ê¸°: {video_info.size_mb:.1f}MB")

        # ì¶”ì¶œ ê°„ê²© ìë™ ê³„ì‚°
        if interval is None:
            optimizer = ContextOptimizer()
            strategy = optimizer.calculate_strategy(video_info.duration)
            interval = strategy.interval_seconds
            print(f"\nğŸ”§ ìë™ ìµœì í™”")
            print(f"   ì¶”ì¶œ ê°„ê²©: {interval}ì´ˆ")
            print(f"   ì˜ˆìƒ í”„ë ˆì„: {strategy.estimated_frames}ê°œ")

        # ìºì‹œ ë§¤ë‹ˆì € ì´ˆê¸°í™”
        cache_manager = CacheManager(auto_cleanup=cleanup_cache)
        frames_dir = cache_manager.create_cache_dir(video_path)

        # í”„ë ˆì„ ì¶”ì¶œ
        print(f"\nğŸ–¼ï¸  í”„ë ˆì„ ì¶”ì¶œ ì¤‘...")
        frames = extractor.extract_frames(
            video_path,
            frames_dir,
            interval=interval,
        )
        print(f"   ì¶”ì¶œ ì™„ë£Œ: {len(frames)}ê°œ í”„ë ˆì„")

        # AI ë¶„ì„
        print(f"\nğŸ¤– AI ë¶„ì„ ì¤‘ (ëª¨ë¸: {model})...")
        connector = AIConnectorFactory.create("gemini", model=model)
        analysis_result = connector.analyze(
            frame_paths=frames,
            interval_sec=interval,
            duration_str=video_info.duration_str,
            custom_prompt=custom_prompt,
            output_language=language,
            working_dir=frames_dir,
        )

        if not analysis_result.success:
            result["error"] = analysis_result.error_message
            return result

        # ê²°ê³¼ êµ¬ì„±
        result["success"] = True
        result["analysis"] = analysis_result.result
        result["metadata"] = {
            "video_name": video_path.name,
            "video_duration": video_info.duration,
            "video_resolution": f"{video_info.width}x{video_info.height}",
            "frame_count": len(frames),
            "interval_seconds": interval,
            "model": model,
            "language": language,
        }

        # ë¶„ì„ ê¸°ë¡ ì €ì¥
        if save_sidecar or save_history:
            record = AnalysisRecord(
                video_path=str(video_path),
                video_name=video_path.name,
                video_duration=video_info.duration,
                video_resolution=(video_info.width, video_info.height),
                video_size_mb=video_info.size_mb,
                extraction_mode="interval" if interval else "all_iframes",
                extraction_interval=interval,
                frame_count=len(frames),
                ai_provider="Gemini",
                prompt_used=analysis_result.prompt_used,
                analysis_result=analysis_result.result,
            )

            store = MetadataStore()
            store.save(
                record,
                save_sidecar=save_sidecar,
                save_to_history=save_history,
            )
            result["record_id"] = record.id

        # ìºì‹œ ì •ë¦¬
        if cleanup_cache:
            cache_manager.cleanup_video_cache(video_path)
            print(f"\nğŸ—‘ï¸  ìºì‹œ ì •ë¦¬ ì™„ë£Œ")

        print(f"\nâœ… ë¶„ì„ ì™„ë£Œ!")

    except Exception as e:
        result["error"] = str(e)

    return result


def list_history(limit: int = 20, output_format: str = "text") -> list[dict]:
    """ë¶„ì„ íˆìŠ¤í† ë¦¬ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤."""
    store = MetadataStore()
    records = store.list_history(limit=limit)

    if output_format == "json":
        return [
            {
                "id": r.id,
                "video_name": r.video_name,
                "video_duration": r.video_duration,
                "frame_count": r.frame_count,
                "created_at": r.created_at,
                "analysis_preview": r.analysis_result[:200] + "..." if len(r.analysis_result) > 200 else r.analysis_result,
            }
            for r in records
        ]

    if not records:
        print("\nğŸ“­ ë¶„ì„ íˆìŠ¤í† ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return []

    print(f"\nğŸ“œ ë¶„ì„ íˆìŠ¤í† ë¦¬ (ìµœê·¼ {len(records)}ê°œ)")
    print("=" * 70)

    for i, record in enumerate(records, 1):
        created = record.created_datetime.strftime("%Y-%m-%d %H:%M")
        print(f"\n{i}. [{record.id[:8]}] {record.video_name}")
        print(f"   ìƒì„±: {created} | ê¸¸ì´: {record.video_duration:.0f}ì´ˆ | í”„ë ˆì„: {record.frame_count}ê°œ")
        preview = record.analysis_result[:100].replace("\n", " ")
        print(f"   ìš”ì•½: {preview}...")

    print()
    return [{"id": r.id, "video_name": r.video_name} for r in records]


def get_history_detail(record_id: str, output_format: str = "text") -> Optional[dict]:
    """íŠ¹ì • ë¶„ì„ ê¸°ë¡ì˜ ìƒì„¸ ë‚´ìš©ì„ ì¡°íšŒí•©ë‹ˆë‹¤."""
    store = MetadataStore()
    record = store.get_from_history(record_id)

    if not record:
        # ë¶€ë¶„ IDë¡œ ê²€ìƒ‰
        records = store.list_history(limit=1000)
        for r in records:
            if r.id.startswith(record_id):
                record = r
                break

    if not record:
        print(f"\nâŒ ê¸°ë¡ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {record_id}")
        return None

    if output_format == "json":
        return {
            "id": record.id,
            "video_path": record.video_path,
            "video_name": record.video_name,
            "video_duration": record.video_duration,
            "video_resolution": record.video_resolution,
            "frame_count": record.frame_count,
            "ai_provider": record.ai_provider,
            "created_at": record.created_at,
            "analysis_result": record.analysis_result,
        }

    print(f"\nğŸ“‹ ë¶„ì„ ê²°ê³¼ ìƒì„¸")
    print("=" * 70)
    print(f"ID: {record.id}")
    print(f"íŒŒì¼: {record.video_name}")
    print(f"ê²½ë¡œ: {record.video_path}")
    print(f"ê¸¸ì´: {record.video_duration:.0f}ì´ˆ")
    print(f"í•´ìƒë„: {record.video_resolution}")
    print(f"í”„ë ˆì„: {record.frame_count}ê°œ")
    print(f"AI: {record.ai_provider}")
    print(f"ìƒì„±ì¼: {record.created_at}")
    print("\n--- ë¶„ì„ ê²°ê³¼ ---\n")
    print(record.analysis_result)
    print()

    return {"id": record.id, "analysis_result": record.analysis_result}


def manage_cache(action: str = "status") -> dict:
    """ìºì‹œë¥¼ ê´€ë¦¬í•©ë‹ˆë‹¤."""
    cache_manager = CacheManager()

    if action == "status":
        size_mb = cache_manager.get_total_size_mb()
        count = cache_manager.get_cache_count()

        print(f"\nğŸ“¦ ìºì‹œ ìƒíƒœ")
        print(f"   ì´ í¬ê¸°: {size_mb:.1f}MB")
        print(f"   ìºì‹œ ìˆ˜: {count}ê°œ")
        print(f"   ìœ„ì¹˜: {cache_manager.cache_dir}")
        print()

        return {"size_mb": size_mb, "count": count, "path": str(cache_manager.cache_dir)}

    elif action == "clean":
        count = cache_manager.cleanup_all()
        print(f"\nğŸ—‘ï¸  ìºì‹œ ì •ë¦¬ ì™„ë£Œ: {count}ê°œ ì‚­ì œ")
        return {"deleted": count}

    elif action == "clean-old":
        count = cache_manager.cleanup_old_cache()
        print(f"\nğŸ—‘ï¸  ì˜¤ë˜ëœ ìºì‹œ ì •ë¦¬ ì™„ë£Œ: {count}ê°œ ì‚­ì œ")
        return {"deleted": count}

    return {}


def main():
    """CLI ë©”ì¸ í•¨ìˆ˜."""
    parser = argparse.ArgumentParser(
        description="Movie File Analyzer CLI - ì˜ìƒ ë¶„ì„ ë„êµ¬",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ì˜ˆì œ:
  # ì˜ìƒ ë¶„ì„
  python -m src.cli analyze video.mp4
  python -m src.cli analyze video.mp4 --interval 5 --model gemini-2.5-flash
  python -m src.cli analyze "https://youtube.com/watch?v=xxx"

  # íˆìŠ¤í† ë¦¬ ì¡°íšŒ
  python -m src.cli history
  python -m src.cli history --limit 10
  python -m src.cli history --id abc12345

  # ìºì‹œ ê´€ë¦¬
  python -m src.cli cache status
  python -m src.cli cache clean

  # ìƒíƒœ í™•ì¸
  python -m src.cli status
        """,
    )

    subparsers = parser.add_subparsers(dest="command", help="ëª…ë ¹ì–´")

    # analyze ëª…ë ¹ì–´
    analyze_parser = subparsers.add_parser("analyze", help="ì˜ìƒ ë¶„ì„")
    analyze_parser.add_argument("input", help="ì˜ìƒ íŒŒì¼ ê²½ë¡œ ë˜ëŠ” YouTube URL")
    analyze_parser.add_argument("--interval", "-i", type=float, help="ì¶”ì¶œ ê°„ê²© (ì´ˆ)")
    analyze_parser.add_argument("--model", "-m", default="auto",
                                choices=["auto", "gemini-2.5-pro", "gemini-2.5-flash", "gemini-2.0-flash"],
                                help="Gemini ëª¨ë¸ (ê¸°ë³¸: auto)")
    analyze_parser.add_argument("--language", "-l", default="korean",
                                choices=["korean", "english", "japanese", "chinese", "auto"],
                                help="ì¶œë ¥ ì–¸ì–´ (ê¸°ë³¸: korean)")
    analyze_parser.add_argument("--prompt", "-p", help="ì‚¬ìš©ì ì •ì˜ ì¶”ê°€ í”„ë¡¬í”„íŠ¸")
    analyze_parser.add_argument("--no-sidecar", action="store_true", help="ì‚¬ì´ë“œì¹´ JSON ì €ì¥ ì•ˆí•¨")
    analyze_parser.add_argument("--no-history", action="store_true", help="íˆìŠ¤í† ë¦¬ ì €ì¥ ì•ˆí•¨")
    analyze_parser.add_argument("--keep-cache", action="store_true", help="ìºì‹œ ìœ ì§€")
    analyze_parser.add_argument("--json", action="store_true", help="JSON í˜•ì‹ìœ¼ë¡œ ì¶œë ¥")

    # history ëª…ë ¹ì–´
    history_parser = subparsers.add_parser("history", help="ë¶„ì„ íˆìŠ¤í† ë¦¬ ì¡°íšŒ")
    history_parser.add_argument("--limit", "-n", type=int, default=20, help="ìµœëŒ€ ê°œìˆ˜ (ê¸°ë³¸: 20)")
    history_parser.add_argument("--id", help="íŠ¹ì • ê¸°ë¡ ID ì¡°íšŒ")
    history_parser.add_argument("--json", action="store_true", help="JSON í˜•ì‹ìœ¼ë¡œ ì¶œë ¥")

    # cache ëª…ë ¹ì–´
    cache_parser = subparsers.add_parser("cache", help="ìºì‹œ ê´€ë¦¬")
    cache_parser.add_argument("action", nargs="?", default="status",
                              choices=["status", "clean", "clean-old"],
                              help="ì‘ì—… (ê¸°ë³¸: status)")
    cache_parser.add_argument("--json", action="store_true", help="JSON í˜•ì‹ìœ¼ë¡œ ì¶œë ¥")

    # status ëª…ë ¹ì–´
    subparsers.add_parser("status", help="ì˜ì¡´ì„± ìƒíƒœ í™•ì¸")

    args = parser.parse_args()

    if args.command is None:
        parser.print_help()
        return

    output_format = "json" if getattr(args, "json", False) else "text"

    if args.command == "status":
        print_status()

    elif args.command == "analyze":
        input_path = args.input

        # YouTube URL ì²˜ë¦¬
        if is_youtube_url(input_path):
            success, message, video_path = download_youtube(input_path)
            if not success:
                if output_format == "json":
                    print(json.dumps({"success": False, "error": message}, ensure_ascii=False))
                else:
                    print(f"âŒ {message}")
                return
            print(f"âœ… {message}")
        else:
            video_path = Path(input_path)

        result = analyze_video(
            video_path=video_path,
            interval=args.interval,
            model=args.model,
            language=args.language,
            custom_prompt=args.prompt,
            save_sidecar=not args.no_sidecar,
            save_history=not args.no_history,
            cleanup_cache=not args.keep_cache,
            output_format=output_format,
        )

        if output_format == "json":
            print(json.dumps(result, ensure_ascii=False, indent=2))
        elif result["success"]:
            print("\n--- ë¶„ì„ ê²°ê³¼ ---\n")
            print(result["analysis"])
        else:
            print(f"\nâŒ ì˜¤ë¥˜: {result['error']}")

    elif args.command == "history":
        if args.id:
            result = get_history_detail(args.id, output_format)
            if output_format == "json" and result:
                print(json.dumps(result, ensure_ascii=False, indent=2))
        else:
            result = list_history(args.limit, output_format)
            if output_format == "json":
                print(json.dumps(result, ensure_ascii=False, indent=2))

    elif args.command == "cache":
        result = manage_cache(args.action)
        if output_format == "json":
            print(json.dumps(result, ensure_ascii=False, indent=2))


if __name__ == "__main__":
    main()
